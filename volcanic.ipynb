{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from time import ctime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotfig (ypred, yactual, strtitle, y_max):\n",
    "    plt.scatter(ypred, yactual.values.ravel())\n",
    "    plt.title(strtitle)\n",
    "    plt.plot([(0, 0), (y_max, y_max)], [(0, 0), (y_max, y_max)])\n",
    "    plt.xlim(0, y_max)\n",
    "    plt.ylim(0, y_max)\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    plt.ylabel('Actual', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alexander Lyubchenko - INGV_TSFresh_7730\n",
    "train = pd.read_csv('../input/ingv-tsfresh-7730/train.csv', sep = ';')\n",
    "train.set_index('Unnamed: 0', inplace = True)\n",
    "test = pd.read_csv('../input/ingv-tsfresh-7730/test.csv', sep = ';')\n",
    "test.set_index('Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = test.index\n",
    "train_rf = train.copy()\n",
    "train_rf = train_rf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_rf.drop('time_to_eruption', axis=1)\n",
    "y = train_rf['time_to_eruption']\n",
    "# Entrainons un modèle simple afin d'estimer l'importance des différentes colonnes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=1, max_depth=7)\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculons le score d'importance de chaque colonne et trions le du plus important au moins\n",
    "feature_scores = pd.Series(model.feature_importances_, index=x.columns).sort_values(ascending=False)\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On garde les 350 features les plus importantes (ancienne méthode)\n",
    "selected_feature = feature_scores[:350].index\n",
    "selected_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = feature_scores.loc[feature_scores >= 0.001].index\n",
    "selected_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['time_to_eruption']\n",
    "# Rassemblons les datasets\n",
    "all_data = pd.concat([train, test], ignore_index = True)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On re-définit notre dataset en gardant seulement les features les plus importantes + la colonne time_to_eruption\n",
    "all_data = pd.concat([all_data[selected_feature], all_data['time_to_eruption']], axis=1)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le taux de valeurs manquantes par colonne\n",
    "def missing_values_table(df):\n",
    "        # Total de valeurs manquantes\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Pourcentage de valeurs manquantes\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Construire un tableau\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Renommer les colonnes\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Tri du tableau du plus de valeurs manquantes au moins\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        \n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"+\"There are \" + str(mis_val_table_ren_columns.shape[0]) + \" columns that have missing values.\")\n",
    "        \n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appel de la méthode missing_values_table()\n",
    "missing_values = missing_values_table(all_data)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna() permet de remplir les valeurs manquantes\n",
    "# .model() permet d'obtenir un set des valeurs les plus présentes dans le dataset\n",
    "all_data = all_data.fillna(all_data.mode())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On adapte le scaler à la data puis on la scale\n",
    "header = all_data.columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "all_data[header] = scaler.fit_transform(all_data)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.drop('time_to_eruption', axis=1)\n",
    "all_data.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = missing_values_table(all_data)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.fillna(all_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de composantes principales (réduction du nb de dimensions)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA() \n",
    "all_data_pca = pca.fit_transform(all_data)\n",
    "all_data_pca = pd.DataFrame(all_data_pca)\n",
    "all_data_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data_pca[:train.shape[0]]\n",
    "test = all_data_pca[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = target\n",
    "X = train\n",
    "grid_params = {\n",
    "    'num_leaves': [24, 25, 26], #[7, 20, 30 ,50], [15, 20, 25]\n",
    "    'learning_rate': [0.04, 0.05, 0.06], #[0.1, 0.03, 0.003], [0.05, 0.1, 0.15]\n",
    "    'max_depth': [4, 5, 6], #[-1, 3, 5], [5, 7, 10]\n",
    "    'n_estimators': [1000, 1500, 2000], #[50, 100, 200, 500],  [500, 700, 800, 1000]\n",
    "}\n",
    "\n",
    "#clf = GridSearchCV(lgb.LGBMRegressor(), grid_params, scoring='r2')\n",
    "#clf.fit(X, Y)\n",
    "\n",
    "#print(\"Best parameters set found on development set:\")\n",
    "#print(clf.best_params_)\n",
    "\n",
    "## {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500, 'num_leaves': 20}\n",
    "## {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 1000, 'num_leaves': 25}\n",
    "## {'learning_rate': 0.04, 'max_depth': 5, 'n_estimators': 2000, 'num_leaves': 26}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMRegressor(learning_rate=0.04,max_depth=5,n_estimators=2000, num_leaves=26) #**clf.best_params_\n",
    "gbm.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = gbm.predict(test, num_iteration=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['segment_id'] = test_index\n",
    "submission['time_to_eruption'] = y_pred\n",
    "submission.to_csv('submission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "y_target = y_test\n",
    "print('The rmse of prediction is:', mean_squared_error(y_target, y_pred) ** 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
